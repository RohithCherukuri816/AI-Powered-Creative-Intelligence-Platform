{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfa8 Doodle Recognition Model Training\n",
    "## Train on Kaggle GPU and Download to Local Machine\n",
    "\n",
    "This notebook will:\n",
    "1. Download Quick Draw dataset (100 categories)\n",
    "2. Preprocess the data\n",
    "3. Train a CNN model\n",
    "4. Evaluate performance\n",
    "5. Export model for download\n",
    "\n",
    "**\u26a0\ufe0f IMPORTANT:** Enable GPU in Kaggle (Settings \u2192 Accelerator \u2192 GPU T4 x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q scikit-learn matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Step 2: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# Configuration\n",
    "CATEGORIES = [\n",
    "    'airplane', 'ambulance', 'angel', 'ant', 'apple', 'axe', 'banana',\n",
    "    'baseball', 'basketball', 'bat', 'bathtub', 'bear', 'bed', 'bee',\n",
    "    'bicycle', 'bird', 'book', 'bread', 'bus', 'butterfly', 'cake',\n",
    "    'car', 'cat', 'chair', 'cloud', 'computer', 'cookie', 'cow',\n",
    "    'crab', 'cup', 'deer', 'dog', 'dolphin', 'donut', 'dragon',\n",
    "    'duck', 'elephant', 'eye', 'face', 'fish', 'flower', 'frog',\n",
    "    'giraffe', 'guitar', 'hamburger', 'hammer', 'hat', 'helicopter',\n",
    "    'horse', 'house', 'ice cream', 'key', 'knight', 'ladder',\n",
    "    'lighthouse', 'lion', 'monkey', 'moon', 'mosquito', 'mouse',\n",
    "    'mushroom', 'octopus', 'owl', 'panda', 'parrot', 'pear',\n",
    "    'penguin', 'piano', 'pig', 'pineapple', 'pizza', 'rabbit',\n",
    "    'raccoon', 'rhinoceros', 'saw', 'scissors', 'sea turtle',\n",
    "    'shark', 'sheep', 'snail', 'snake', 'snowman', 'spider',\n",
    "    'squirrel', 'star', 'strawberry', 'swan', 'sword', 'table',\n",
    "    'teapot', 'teddy-bear', 'telephone', 'tiger', 'train', 'tree',\n",
    "    'truck', 'umbrella', 'van', 'violin', 'watermelon', 'whale',\n",
    "    'wheel', 'windmill', 'zebra'\n",
    "]\n",
    "\n",
    "SAMPLES_PER_CATEGORY = 10000\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('plots', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce5 Step 3: Download Quick Draw Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_category(category, base_url, samples_limit=None):\n",
    "    filename = f\"{category.replace(' ', '_')}.npy\"\n",
    "    url = f\"{base_url}/{filename}\"\n",
    "    filepath = os.path.join('data', filename)\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        print(f\"\u2705 {category} already downloaded\")\n",
    "        return filepath\n",
    "    \n",
    "    try:\n",
    "        print(f\"\ud83d\udce5 Downloading {category}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        \n",
    "        with open(filepath, 'wb') as file:\n",
    "            with tqdm(total=total_size, unit='B', unit_scale=True) as pbar:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "                        pbar.update(len(chunk))\n",
    "        \n",
    "        if samples_limit:\n",
    "            data = np.load(filepath)\n",
    "            if len(data) > samples_limit:\n",
    "                np.save(filepath, data[:samples_limit])\n",
    "        \n",
    "        print(f\"\u2705 {category} downloaded\")\n",
    "        return filepath\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Failed: {e}\")\n",
    "        return None\n",
    "\n",
    "base_url = \"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap\"\n",
    "print(f\"\ud83d\udce5 Downloading {len(CATEGORIES)} categories...\")\n",
    "for category in CATEGORIES:\n",
    "    download_category(category, base_url, SAMPLES_PER_CATEGORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd04 Step 4: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(categories, samples_per_category):\n",
    "    print(\"\ud83d\udcc2 Loading data...\")\n",
    "    all_data, all_labels = [], []\n",
    "    \n",
    "    for category in tqdm(categories, desc=\"Loading\"):\n",
    "        filename = f\"{category.replace(' ', '_')}.npy\"\n",
    "        filepath = os.path.join('data', filename)\n",
    "        \n",
    "        if not os.path.exists(filepath):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            data = np.load(filepath)\n",
    "            if samples_per_category and len(data) > samples_per_category:\n",
    "                data = data[:samples_per_category]\n",
    "            all_data.append(data)\n",
    "            all_labels.extend([category] * len(data))\n",
    "        except Exception as e:\n",
    "            print(f\"\u274c Error loading {category}: {e}\")\n",
    "    \n",
    "    X = np.vstack(all_data)\n",
    "    y = np.array(all_labels)\n",
    "    print(f\"\u2705 Loaded {len(X):,} samples across {len(set(y))} categories\")\n",
    "    \n",
    "    print(\"\ud83d\uddbc\ufe0f Preprocessing...\")\n",
    "    X = X.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "    X = 1.0 - X\n",
    "    \n",
    "    print(\"\ud83c\udff7\ufe0f Encoding labels...\")\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_int = label_encoder.fit_transform(y)\n",
    "    y_categorical = to_categorical(y_int)\n",
    "    \n",
    "    return X, y_categorical, label_encoder\n",
    "\n",
    "X, y, label_encoder = load_and_preprocess_data(CATEGORIES, SAMPLES_PER_CATEGORY)\n",
    "\n",
    "print(\"\u2702\ufe0f Splitting data...\")\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"Training: {len(X_train):,}\")\n",
    "print(f\"Validation: {len(X_val):,}\")\n",
    "print(f\"Test: {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfd7\ufe0f Step 5: Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    return models.Sequential([\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = build_model(num_classes)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy')]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfcb\ufe0f Step 6: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint('models/best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\ud83d\ude80 Starting training...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"\u2705 Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Step 7: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\ud83d\udcca Evaluating...\")\n",
    "test_loss, test_accuracy, test_top3 = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 Results:\")\n",
    "print(f\"   Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"   Top-3: {test_top3:.4f}\")\n",
    "print(f\"   Loss: {test_loss:.4f}\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax1.plot(history.history['accuracy'], label='Train')\n",
    "ax1.plot(history.history['val_accuracy'], label='Val')\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2.plot(history.history['loss'], label='Train')\n",
    "ax2.plot(history.history['val_loss'], label='Val')\n",
    "ax2.set_title('Loss')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/training_history.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcbe Step 8: Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/doodle_classifier.h5')\n",
    "print(\"\u2705 Model saved\")\n",
    "\n",
    "with open('models/label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "metadata = {\n",
    "    \"model_name\": \"doodle_classifier\",\n",
    "    \"class_names\": label_encoder.classes_.tolist(),\n",
    "    \"num_classes\": len(label_encoder.classes_),\n",
    "    \"input_shape\": [28, 28, 1],\n",
    "    \"test_accuracy\": float(test_accuracy),\n",
    "    \"test_top3_accuracy\": float(test_top3),\n",
    "    \"test_loss\": float(test_loss),\n",
    "    \"model_parameters\": int(model.count_params()),\n",
    "    \"training_samples\": len(X_train),\n",
    "    \"preprocessing\": {\"normalize\": True, \"invert_colors\": True, \"resize_to\": [28, 28]}\n",
    "}\n",
    "\n",
    "with open('models/doodle_classifier_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "with open('models/class_names.json', 'w') as f:\n",
    "    json.dump(label_encoder.classes_.tolist(), f, indent=2)\n",
    "\n",
    "print(\"\u2705 Metadata saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 Step 9: Create Download Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "export_dir = 'export_for_local'\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "shutil.copy('models/doodle_classifier.h5', export_dir)\n",
    "shutil.copy('models/doodle_classifier_metadata.json', export_dir)\n",
    "shutil.copy('models/label_encoder.pkl', export_dir)\n",
    "shutil.copy('models/class_names.json', export_dir)\n",
    "shutil.copy('plots/training_history.png', export_dir)\n",
    "\n",
    "print(\"\u2705 Files ready in export_for_local/\")\n",
    "print(\"\\n\ud83d\udcc1 Files to download:\")\n",
    "for file in os.listdir(export_dir):\n",
    "    size_mb = os.path.getsize(os.path.join(export_dir, file)) / (1024 * 1024)\n",
    "    print(f\"   - {file} ({size_mb:.2f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Step 10: Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(len(X_test), 10, replace=False)\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    image = X_test[idx]\n",
    "    true_label = label_encoder.classes_[y_test[idx].argmax()]\n",
    "    pred = model.predict(image.reshape(1, 28, 28, 1), verbose=0)[0]\n",
    "    pred_label = label_encoder.classes_[pred.argmax()]\n",
    "    confidence = pred.max()\n",
    "    \n",
    "    axes[i].imshow(image.squeeze(), cmap='gray')\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    axes[i].set_title(f'{true_label}\\n{pred_label} ({confidence:.2f})', fontsize=8, color=color)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/predictions.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 Training Complete!\\n",
    "\\n",
    "### Download Instructions:\\n",
    "\\n",
    "1. **In Kaggle:** Click Output tab \u2192 export_for_local \u2192 Download\\n",
    "2. **On Local Machine:** Copy files to `colab_backend/models/`\\n",
    "3. **Update Code:** Edit `colab_backend/recognizer.py`:\\n",
    "\\n",
    "```python\\n",
    "def __init__(self):\\n",
    "    import os, json, tensorflow as tf\\n",
    "    model_path = \"models/doodle_classifier.h5\"\\n",
    "    if os.path.exists(model_path):\\n",
    "        self.model = tf.keras.models.load_model(model_path)\\n",
    "        with open(\"models/doodle_classifier_metadata.json\") as f:\\n",
    "            self.classes = json.load(f)['class_names']\\n",
    "        print(f\"\u2705 Loaded: {len(self.classes)} classes\")\\n",
    "```\\n",
    "\\n",
    "4. **Run:** `npm run dev`\\n",
    "\\n",
    "Your model is ready! \ud83d\ude80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"\ud83c\udf89 TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Top-3: {test_top3:.4f} ({test_top3*100:.2f}%)\")\n",
    "print(f\"Classes: {num_classes}\")\n",
    "print(f\"Parameters: {model.count_params():,}\")\n",
    "print(\"\\n\ud83d\udce5 Download 'export_for_local' folder from Output tab\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}